Because spaces may be included in the text, regular expressions shown here are to be used excluding the outermost brackets.

Using internet archive's email (savepagenow@archive.org) page saver:
	Before we begin, the IA returns the email back to the user to indicate
	if the links actually saved or not. It is formatted like this:
	<Line number>. <URL address> <Status>
	
	<Line number>:
		Used for listing each URL. Not actually part of the text and acts as [<ol><li>...</li></ol>]
		in HTML.
	<URL address>:
		Indicates what URL the WBM have saved. When successful, will show the archive URL, otherwise
		if failed ("Error!"), displays the original URL.
	<Status>:
		When saving the URL for the first time, will say "First Archive", otherwise
		if saving a URL that was previously saved, won't display anything, otherwise
		if saving a URL results in a fail, outputs these errors:
			Error! Browser timeout for <URL address>
			Error! Capture timed out
			Error! Expecting value: line 1 column 1 (char 0)
			Error! Internal Server Error for <URL address> (HTTP status=500)
			Error! Job failed
			Error! Live page is not available: <URL address>
			Error! System proxy error for URL <URL address>
			Error! The server didn't respond in time for <URL address>
			Error! The server response status was 502.
	
	Follow these instructions in order to retry saving a link:
		Convert IA links back to normal links:
			(1) Remove the IA's string part of the URL:
				Find what: [https\:\/\/web\.archive\.org\/web\/[0-9]*\/]
				Replace with: [] (nothing)
		
			(2) Remove all stuff after the URLs:
				Find what: [ Error! .*$]
				Replace with: [] (nothing)
				Wrap around: checked
				. matches newline: unchecked
	You should now have the URLs that didn't save, just submit those and repeat until all links are successful. However, if you have
	links with special/non-UTF characters, try saving via HTML-styled hyperlinks:
		If the URL contains special characters and non-UTF characters (which often results in emails that characters on or after the first invalid character are ignored),
		create a blank HTML file and paste the URLs formatted as a list with each line containing exactly 1 link. Then use Notepad++'s regular expression feature
		to add this:
		
			Find what: [^]
			Replace with: [<a href="]
			
		then do this:
			
			Find what: [$]
			Replace with: [">Link</a>]
			
		Save and then open the HTML file with a browser (preferably Firefox or chrome), copy all the text and paste them into the email. During copying and pasting,
		it should also copy the format and not just text (in this case, clickable hyperlinks). That way, the internet archive will save the WHOLE URL strings and not just
		try to save the first n characters that are "valid".
		
		Note!: It is possible that mojibakes can occur, which is why it is mostly recommended to get the percent encoded form instead.
		
		If you are saving pages on twitter, please read the “Email saving used on twitter” as there is another possibility of not saving pages.
		
	Email saving used on twitter.
		Due to the new twitter layout, make sure you have these extensions:
			GoodTwitter: https://github.com/ZusorCode/GoodTwitter
			Link gopher: https://github.com/az0/linkgopher/
			
			If you use link Gopher, it will extract all CURRENTLY LOADED links in the HTML file. So by loading stuff (scrolling down) on the bottom,
			they will be caught by the extension too.
			
		When saving tweets on twitter, it's possible that saving any twitter pages can randomly redirect to:
		[https://api.twitter.com/2/timeline/conversation/<TweetID>.json?<long string of commands>]
		[https://twitter.com/i/js_inst?c_name=ui_metrics]
		[https://pbs.twimg.com/hashflag/config-<year>-<month>-<day>-16.json]
		
		When a redirect happens, currently, the WBM will simply show the URL redirected to, not the link you gave it.
		To retry these redirected links, follow these instructions:
		
			Have 2 lists. One containing the links you sent, and the links you got back. Make sure both lists are formatted
			with 1 URL on each line, and the one you sent must be sorted alphabetically (Edit -> Line Operations -> Sort lines Lexicography ascending)
			and MAKE SURE YOU REMOVE DUPLICATES HERE (Edit -> Line Operations -> Remove Consecutive Duplicate lines). Having duplicates in the list you
			sent to the IA will not show up the links redirected.
			
			On the links you got back from a reply, convert them into regular non-archive links (“Convert IA links back to normal links”). You should
			now have 2 almost-identical links.
			
			Combine the lists: Take one, and paste it on the bottom of the other (don't paste it positioned so that the pasted list's first URL is on
			the same line as the other list's last item, there should still be 1 URL per line).
			
			Sort the URLS alphabetically (Edit -> Line Operations -> Sort lines Lexicography ascending).
			This will caused duplicate lines that have not been redirected to be placed next to another.
			This time, do NOT remove duplicates, they're there to indicate that they weren't redirected,
			doing that will just reduce all duplicates to one instead of getting a URL that only exists once.
			
			Make a line break on the last item on the bottom.
			
			Replace by doing this:
				Find what box: [(?-s)^(.+\R)\1+]
				Replace with box: [] (empty)
				Search mode radiobutton: Regular expression
				Wrap around checkbox: ticked
				. matches newline checkbox: doesn’t matter (because the (?-s) leading off the Find what box contains an s variant)
				
			Then press the Replace All button. This looks for 2 adjacent lines that are exactly the same, if they are, then
			remove all that duplicates (those are URLs you sent and the same you got back from reply). If there are only one (you sent a URL, and
			returns a different URL from reply, which is a redirected link), then leave it there.